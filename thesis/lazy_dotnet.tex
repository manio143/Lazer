% Copyright (c) 2020 by Marian Dziubiak <marian.dziubiak@gmail.com>

\documentclass[en]{pracamgr}

\usepackage{color}
\usepackage{hyperref}
\usepackage{graphicx}

% Dane magistranta:
\autor{Marian Dziubiak}{370784}

\title{Implementation of a lazy runtime environment on the .NET platform}
\titlepl{Implementacja leniwego środowiska uruchomieniowego na platformie .NET}

%kierunek: 
% - matematyka, informacyka, ...
% - Mathematics, Computer Science, ...
\kierunek{Computer Science}

% Praca wykonana pod kierunkiem:
% (podać tytuł/stopień imię i nazwisko opiekuna
% Instytut
\opiekun{dr Marcin Benke\\
  Institute of Informatics\\
  }

% miesiąc i~rok:
\date{May 2020}

%Podać dziedzinę wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
11.3 Computer Science\\ 
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{Software and its engineering\\
  Software notations and tools\\
  Compilers\\
  Runtime environments}

% Słowa kluczowe:
\keywords{functional programming, lazy evaluation, .NET CLR}

% Tu jest dobre miejsce na Twoje własne makra i~środowiska:
\newtheorem{defi}{Definicja}[section]
\newcommand{\shrp}{%
  {\settoheight{\dimen0}{C}\kern-.05em \resizebox{!}{\dimen0}{\raisebox{\depth}{\textbf{\#}}}\hspace{1ex}}}
\newcommand{\myref}[1]{\ref{#1}.~\nameref{#1}}

\definecolor{brown}{RGB}{104,55,0}
\definecolor{gray}{RGB}{110,110,110}
\hypersetup{
    colorlinks,
    linkcolor=brown,
    citecolor=gray,
    urlcolor=blue
}

% koniec definicji

\begin{document}
\maketitle

\begin{abstract}
  TODO: Write a nice abstract
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

% ##########################
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
% ##########################

Functional programming is reliving a peak in its popularity.
One of the more interesting features of pure functional programming
is lazy evaluation. This means delaying the evaluation of an expression
until its value is actually needed. This allows the programmer to use
infinite data structures and certain types of algorithms that wouldn't
be possible in a strict language. Currently the main programming language
supporting lazy evaluation is Haskell.

Haskell is compiled to native code or to LLVM representation by~the~optimizing
compiler GHC. Like many other programming languages Haskell is mostly
tied to its compiler and the native platform (as opposed to a~managed platform).
Actually, Haskell did in fact have more compilers available, however,
GHC is leading the language development and left competition far behind.
There exist a couple of managed platforms that provide a common ecosystem
for multiple languages. The two most popular are JVM and .NET.
There has been some work done for the JVM \cite{Tullsen} \cite{Choi} \cite{Alliet}
and there exist two Haskell implementations: 
\href{https://github.com/Frege/frege}{Frege}~and~\href{https://eta-lang.org/}{Eta}.
In~this work I will focus on the idea of bringing
Haskell to the .NET platform. \\

In 2002 Microsoft has released the first version of .NET Framework with
C\shrp programming language. Since the initial release, the .NET ecosystem
has grown mature with many languages targeting the platform. 
Some of them are functional programming languages -- \mbox{F\shrp, SML.NET, Nemerle}.
In 2015 most of the platform has been open sourced and gained a lot of
interest from the community. This lead to some interesting performance
improvements.\\ \\
Previous attempts to bring
Haskell to the .NET CLR (\textit{Common Language Runtime}):
\begin{itemize}
  \item
  In 2001 Nigel Perry, Erik Meijer and Arjan van Yzendoorn implemented a 
  non-strict scripting language called Mondrian
  \cite{MondrianImplDetails}\cite{PerryMeijer}.
  
  \item
  In 2005 Monique Monteiro, Mauro Ara\'ujo, Rafael Borges and Andr\'e Santos
  created Haskell.NET
  \cite{Brazil}.

  \item
  In 2006 Oliver Hunt created a compiler from Core language to C\shrp, leveraging
  OOVM (\textit{Object Oriented Virtual Machine}) features to simplify interoperability
  with non-strict code from CLI languages \cite{Hunt}.
\end{itemize}

What is the reason for bringing Haskell to a managed platform?\\There will be
additional performance overhead, but the generated code will be portable
and users can leverage a~variety of libraries, including the mature web framework
ASP.NET. This also goes the other way -- .NET developers could access some of
the libraries in the Hackage package repository.

\section*{Chapter contents}

Chapter \myref{r:lazyEval} takes a closer look at semantics of lazy evaluation,
the data structures involved, and the storage of information on the stack vs on the heap. \vspace{.7ex}\\
Chapter \myref{r:funApp} describes the two popular application mechanisms -- \\
\textit{Push/Enter} and \textit{Eval/Apply}, how do they work on
a~stack based OOVM such as CLR, and which seems better. \vspace{.7ex}\\
Chapter \myref{r:lowlevel} describes mechanisms in the CLR that allow
for valid and performant execution of a lazy program -- mainly tail calls
and function pointers. \vspace{.7ex}\\
Chapter \myref{r:runtime} showcases an implementation of a lazy runtime,
building on the concepts introduced in previous chapters. \vspace{.7ex}\\
Chapter \myref{r:alternatives} compares this and other implementations by
showing important differences and arguing for their pros and cons. \vspace{.7ex}\\
Chapter \myref{r:perf} looks at performance bottlenecks, presents
benchmark results and compares those to Haskell compilers. \vspace{.7ex}\\
Chapter \myref{r:compiler} presents some aspects of the translation
mechanism from STG representation of a Haskell program into C\shrp. \vspace{.7ex}\\
Chapter \myref{r:future} looks into future improvements to the runtime
and extending Haskell for CLI interoperability.

% ##########################
\chapter{Lazy evaluation}\label{r:lazyEval}
% ##########################

Every high level programming language has some form of expressions.
They are used to represent algebraic operations, application of
functions or method calls, access to fields of an object, and many more.
When the program is compiled expressions are converted to chains of
instructions that will be executed. In most languages those instructions
are executed at the spot where the expression has appeared in the program.
This means that the order of expression evaluation is explicitly provided
by the programmer (or defined by the language semantics i.e. order of function arguments).
We call this evaluation strategy \textit{strict}.

On the other hand we can delay the evaluation and instead construct
a promise of a value, which we will call a \textit{thunk}, that is passed around
and evaluated only when the promised value is actually needed.
This strategy is called \textit{non-strict}. There is one more thing
necessary to achieve \textit{laziness} -- after a value has been evaluated
any future reference to the promise should return the value without
the need to repeat the computation. In other words, the expression
is evaluated at most once.

With lazy evaluation the order of evaluation is less obvious and thus
programmers don't rely on it for correctness. However, they still have
the tools to control evaluation order which is needed when dealing with
certain operations, i.e. through the use of monads. 
Full program laziness forces purity of functions.
A pure function has no side effects -- it cannot modify the global state.
From this follows referential transparency \cite{referentialTransparency},
a property that allows
replacement of an expression by the value it evaluates to.
Therefore if an expression is used twice it can be evaluated only once.
In contrast an impure expression with side effects has to be reevaluated
every time it occurs.

In most strict languages there is a minimal amount of laziness
in conditional expressions. For example: if the left argument of the
boolean \texttt{\&\&} operator is false then the right argument is not
evaluated. This is especially useful when strict evaluation would lead
to an error.

There are a couple reasons why using lazy evaluation can be beneficial.
First of all it allows to think about certain problems in more mathematical
ways -- i.e. list of all prime numbers. Such a data structure cannot
be computed in finite memory, but it's possible to operate on it as if it
was. This is especially important when dealing with Big Data as large
amounts of information cannot be kept fully in memory, but their subset can.
This is leveraged by frameworks such as Spark and found to increase performance
of computations \cite{lazySpark}. Lazy evaluation also allows to avoid
performing expensive computations when the result is not going to be used.
If we are passing a value to an unknown function we don't know if it 
will be used. In a strict language this computation would have to
be performed either way. Finally, there exist certain data structures that
leverage lazy evaluation to provide amortization of asymptotic complexity,
i.e. queues \cite{amortized}.

\section{Closures and Thunks}\label{s:closures}

There have been a few solutions to the problem of implementing lazy evaluation:
lazy SECD machine \cite{SECDM}, G-Machine \cite{G-Machine}, 
combinator machines (i.e. SKIM) \cite{combinators},
Categorical Abstract Machine (CAM) \cite{CAM}, 
Three-Instruction-Machine (TIM) \cite{TIM} and others.
All of those are approaches to implementing efficient expression graph reductions
as a means of expression evaluation.
This work focuses on the STG-Machine \cite{STGM} which is the mechanism used
in the Glasgow Haskell Compiler (GHC).

The Spineless Tagless G-Machine (STGM) is a concrete implementation of the STG language.
The language is an extension of lambda calculus and this chapter presents
the \texttt{let-in} and \texttt{case-of} expressions that are
used for delaying and forcing expression evaluation.
In STG functions can be applied only to \textit{atoms} -- declared constants or simple
value literals. In order to pass an expression to a function it first has to be
let-bound:

\begin{verbatim}
  let x = expr in f x
\end{verbatim}

For \texttt{x} to be lazy, the \texttt{let-in} expression is interpreted as an
allocation of a \textit{thunk} -- the delayed computation. 
In general, a \textit{closure} is an object with a pointer
to some code and possibly some set of data.
A thunk is a special kind of a closure -- it is represented
by a pointer to the code that evaluates \texttt{expr}, a set of captured
free variables and an update mechanism that allows to return the
evaluated value on any future requests.

The only time a thunk is evaluated (forced) is when its value has to be scrutinized.
This is done by a \texttt{case-of} expression which checks the evaluated value
and performs an alternative selection. Each alternative is represented by a
pattern -- a data constructor or a value literal, and an expression to be evaluated
if the pattern matches the scrutinized value. There also can be a default alternative.
The alternatives in a case expression have to be saturated -- there cannot be a value
that matches no alternative.

\begin{verbatim}
  case x of
    DEFAULT -> expr3
    1 -> expr1
    0 -> expr2
\end{verbatim}

It is worth noting that \texttt{let-in} expression may not always create a thunk.
It turns out that in many cases laziness can cause a slow down in a function
that operates strictly -- scrutinizes its arguments. Therefore a process 
called strictness analysis is
performed by the compiler to decide if a value should be evaluated lazily or
eagerly \cite{demand analysis}.

In particular, expressions that apply a data constructor to the correct number
of arguments (saturated application) are executed eagerly. However, the
arguments may still point to thunks, so lazy semantics are kept.
Constructed data values are also closures and can be scrutinized
in a case expression. Their code is simple as no computation needs to be
performed and the closure body contains the provided arguments.

\section{Operating on the heap vs. on the stack}

There are two main approaches to managing memory usage for program variables.
The stack allows to allocate objects in memory in a sequential manner.
The deallocation has to be performed in a reverse order -- you cannot
reuse memory below the newest variable.
The heap allows to allocate objects in a non-sequential manner which allows
for greater memory reusability, but this has an additional cost.
Programs usually make use of both of those memory structures.

On the .NET platform the heap is maintained by a garbage collector (GC)
that performs complicated algorithms to deallocate objects and
reclaim and compact memory. Thus, using fewer allocations is recommended
to increase performance. However, when it comes to lazy evaluation it
is impossible to do it purely on the stack as the number of created objects
is quite large and their lifetimes less predictable than with strict evaluation.

The operational stack consists of function frames. A frame is the
return pointer to the previous function, local variables and in some cases
arguments to the next called function.
When calling a function a frame for it has to be allocated and later removed when
returning from that function.
It turns out that making such calls is rather expensive -- this can be especially seen
in recursive functions and a reason for them being less popular in 
imperative programming. Tail calls can be used to mitigate frame allocations.
A tail call is such a call that it is the last operation before the function returns.
So the \texttt{call} and \texttt{return} instructions
can be replaced by a \texttt{jump} instruction.

Haskell programs compiled with GHC operate on the stack in a ``non-standard'' way
due to many optimizations. On the .NET platform the stack is used according to the
\texttt{x86\_64} ABI. Moreover, the .NET stack has a fixed size, whereas GHC can manipulate its stack size.
This means extensive non-tail calls usage can lead to a stack overflow and program crash.
In order to maximize tail calls the runtime described in chapter \myref{r:runtime}
uses heap allocated continuations.

All constructed data values, thunks and other closures (i.e. functions) are heap allocated.
This means they are passed around in the form of pointers.
\textit{Unlifted} values such as integers and floating point values
are passed around in their native form.
Pointers and unlifted values may be kept on the stack
for non-tail function calls when a lifted value has to be scrutinized in
an unlifted-returning function (see \{TODO ref\} for details).

% ##########################
\chapter{Function application}\label{r:funApp}
% ##########################

In functional languages, unlike in many imperative languages,
functions are first-class values. This means functions may be passed
to other functions or return new functions, just as easily as manipulating
numbers. Although some languages, like C, have function pointers, they don't
allow for the simplicity of manipulating functions that are offered
by \textit{lambda expressions}.

A lambda expression is of the form $\lambda x. \mathsf{expr}$ and describes
a function that takes an argument $x$ and returns the value of the expression
with $x$ substituted by the value it is applied to. A function that takes
multiple arguments can be described by nested lambda expressions
(i.e.~$\lambda x.\lambda y. x+y$). This is called \textit{currying} after
the work of Haskell Curry in combinatory logic \cite{Curry}.
Another property of lambda expressions is the ability to capture
values of free variables from the enclosing environment.
A variable is free if it is not provided as an argument
(i.e.~in~$\lambda x. x + y$ the variable $y$ is free).
In the implementation of a lambda expression a closure has to
be created that holds its free variables and can be accessed by the
code of the inner expression. Function values described above satisfy
the definition of a \textit{closure} in \myref{s:closures}.

In a program there will be top-level functions whose free variables
can only be other top-level constants and local functions instantiated
each time their binding expression is evaluated.
We differentiate between known and unknown functions.
A function that is known can be applied by simply
calling it with all the required arguments (\textit{saturated application}).
If there's not enough arguments or the function is unknown then it has
to be applied, possibly partially.

Partial application is a technique that allows providing less than
the required number of arguments to a function.
A partially applied function is a function
that takes the remaining arguments and then applies the original function
to the previously and currently provided arguments.

\begin{verbatim}
  f = \x y -> x + y
  g = f 1           -- g = \y -> f 1 y
\end{verbatim}

Partial applications are common in functional programming.
They allow to write succinct code in applicative style and often
abstract out dependencies of a function.

\begin{verbatim}
  let sort = \order -> \list -> ...
  let sortAsc = sort (<=)
  let sortDsc = sort (>=)
\end{verbatim}

There are two common ways of applying unknown functions:
\textit{Push/Enter} and \textit{Eval/Apply}. They are described
below, according to the
definitions by Simon Marlow and Simon Peyton Jones \cite{fastcurry}.

\section{Push/Enter}
In this model each function is responsible for handling its arguments.
The caller \textit{pushes} available arguments on the stack and calls the
function entry point (\textit{enters} the function).
The function inspects the stack to see if it was called with the
sufficient number of arguments and if so pops the arguments from
the stack and begins evaluation of its body. If there's not enough
arguments then the function creates a partial application object (PAP)
and returns that. If there is more than enough arguments then the result
of the function will be also entered.

Usually this means each function gets a slow and a fast entry point.
The slow entry point is responsible for checking the stack, removing
pending arguments and either creating a PAP or calling the fast entry point.

The reason \textit{Push/Enter} was popular is the simplicity of
making a call. No matter what the function being applied is,
the caller pushes arguments on the stack and enters the closure.
Before the introduction of \texttt{x86\_64} there weren't many
general purpose registers so passing arguments on the stack made
more sense.

In the GHC the stack holds both arguments and continuations, but that is
less than optimal in the strongly typed managed environment as it would
require a lot of type checks. Therefore, when implementing this model,
a separate argument stack can be used and a separete continuation stack.
The arguments between continuations have to be
separated in some way. In \cite{Brazil} the sizes of HSNET's stacks',
which represent argument stacks for each primitive type (int, float, closure),
are pushed onto an update stack, zeroed, and later restored.

The stacks can either be accessible from a static object, or passed
to each method in a context object. A context object may be preferred
as it allows for future introduction of multithreading.

\begin{verbatim}
  class Context {
      public Stack<Closure> ArgumentsStack;
      public Stack<Continuation> ContinuationStack;
  }

  class Plus_function : Function {
      public override Closure Enter(Context ctx) {
          if (ctx.ArgumentsStack.Count >= 2) {
              var x1 = ctx.ArgumentsStack.Pop();
              var x2 = ctx.ArgumentsStack.Pop();
              return FastEnter(ctx, x1, x2);
          } else if (ctx.ArgumentsStack.Count == 0) {
              return this;
          } else {
              return new PAP(this, ctx.ArgumentsStack.Pop());
          }
      }
      public static Closure FastEnter(Context ctx, Closure x1, Closure x2) {
          var a1 = x1.Enter(ctx);
          var a2 = x2.Enter(ctx);
          return new Number(a1 + a2);
      }
  }
\end{verbatim}

\section{Eval/Apply}
The second model requires the caller to inspect the arity of a function and
pass it the exact number of arguments. This means it is the caller,
rather than the callee, that creates a PAP if there's not enough arguments.
The caller first has to \textit{evaluate} the function, to check its arity, and then
\textit{apply} it to the arguments.

To make function application easier on the caller function, a set of helper functions
are created that do evaluation and application.

\begin{verbatim}
  public static Closure ApplyHelper(Context ctx, 
                                    Closure func, Closure arg1, Closure arg2) {
      if (func is Function f) {
          // check f's arity
          // if arity = 2 then apply f to all arguments
          // if arity < 2 then apply f to some arguments and
          //    then use a helper to apply the rest
          // if arity > 2 then create a PAP
      } else if (func is PAP p) {
          // extract previous parameters from p
          // apply all available parameters to function in p
      } else if (func is Data) {
          throw new Exception("Cannot apply data");
      } else {
          // eval func and use helper again
      }
  }
\end{verbatim}

This way only one function entry has to be generated and most arguments
will be passed through registers. This style of argument passing is
native to the .NET CLR where JIT (\textit{Just-In-Time} compiler) generates
codes compliant with \texttt{x86\_64} ABI and can potentially be subject to
some additional optimizations.

This model is used in the lazy runtime in chapter \myref{r:runtime}.

% ##########################
\chapter{Low level CLR features}\label{r:lowlevel}
% ##########################

The C\shrp language is usually considered a high-level language.
However, it has some low-level features allowing the user to
manipulate pointers in \texttt{unsafe} contexts.
Moreover, the Common Intermediate Language (CIL) has additional
instructions not available to C\shrp developers.

\section{Tail calls}

One of those CLR \textit{intrinsics} is the tail call modifier.
It is used to force the JIT to emit a tail call.
The \texttt{.tail} modifier has to be placed before a \texttt{call},
\texttt{callvirt} or \texttt{calli} instruction that is followed by
\texttt{ret} instruction. However, in most cases when the JIT is
working in Release mode, or with the Optimized flag, it will
emit tail calls correctly even without the modifier. Sometimes,
especially for long functions, the JIT won't emit a tail call
on its own and in those cases it would be beneficial to decorate
all tail calls with the \texttt{.tail} modifier. Currently the
C\shrp compiler doesn't allow such decorations and this would
therefore require the Haskell to .NET compiler to emit CIL bytecode
directly.

\begin{verbatim}
    .tail
    call int64 class Code::f(int64, int64)
    ret
\end{verbatim}

\section{Function pointers}

Another useful CLR intrinsic instruction is \texttt{ldftn}.
It allows the user to obtain a pointer to a function.
Such a pointer can be then used as an argument to a
 \texttt{calli} instruction.
There may be security issues involved in dealing with function
pointers when the program makes use of dynamically loaded application
domains (when calling a function from an unloaded domain), but
those are outside the scope of this project.
The C\shrp compiler in the version 8.0 doesn't allow for obtaining
function pointers and in this work a modified compiler has been used
to overcome this limitation.

\begin{verbatim}
    ldftn Closure class Code::sfoldl_Case(StgContext, Closure, Closure)
\end{verbatim}

There exists a `safe' function pointer in the form of a \texttt{delegate}.
However, comparison of runtime performance between creating delegates and
using function pointers shows the superiority of the latter (2-3x faster)
\cite{ldftnVSdelegate}.

\section{Switch statements}

When dealing with case expressions with many alternatives the C\shrp compiler
can emit a \texttt{switch} instruction that uses a lookup table to improve
performance. This can only happen when switching on integers and may be
a motivation to add a number tag to each data constructor.
However, for types with a small number (less than five) of
data constructors it appears that a linear switch on their types is faster
than using a number tag, because the necessary type cast is used
to compare cases.

\begin{verbatim}
    switch (variable.Tag) {               switch (variable) {
        case 1:                              case Con1 c1: ...
            var c1 = variable as Con1;       case Con2 c2: ...
            ...                              case Con3 c3: ...
        case 2:                              default: ...
            var c2 = variable as Con2;    }
            ...
        case 3: 
            var c3 = variable as Con3;
            ...
        default: ...
    }
\end{verbatim}

% ##########################
\chapter{Lazy runtime}\label{r:runtime}
% ##########################

intro to why I used C\# with a modified compiler

\section{Closures}

\section{Continuations}

\section{Context object}

\section{Function application}

\section{Algebraic data types}

\section{Universal closures}

\section{Example user code implementation}


% ##########################
\chapter{Comparison to related work}\label{r:alternatives}
% ##########################

\section{JVM based solutions}
In general, issues with tail calls, Tullsen and Choi
\subsection{Eta}
Achievements, issues, similarities and differences

\section{Mondrian}
\cite{PerryMeijer}

\section{Haskell.NET}
\cite{Brazil}

\section{Oliver Hunt's work}
\cite{Hunt}

% ##########################
\chapter{Performance}\label{r:perf}
% ##########################

TODO

\section{Bottlenecks}
\subsection{Branching}
\subsection{Garbage Collection}
stack length and traversing for pointers \\
continuation pooling (update and identity)
\subsection{Method devirtualization}
\subsection{Derivable data classes}
\subsection{Data structures}
continuations stack implementation (System.Stack vs Pointer linked list) \\

% ##########################
\chapter{Compiling Haskell to C\#}\label{r:compiler}
% ##########################

\section{GHC compiler library}

\section{Translating STG}

\section{Optimizations}

% ##########################
\chapter{Future work}\label{r:future}
% ##########################

TODO


\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliography}

\bibitem[MT-96]{Tullsen} Mark Tullsen, \textit{,,Compiling Haskell to Java''}, YALEU/DCS/RR-1204
1996.

\bibitem[BA-07]{Alliet} Brian Alliet, \textit{,,Efficient Translation of Haskell to Java
Master’s Thesis Proposal''}, 2007.

\bibitem[KC,HL,TH-01]{Choi} Kwanghoon Choi, Hyun-il Lim, Taisook Han, \textit{,,Compiling Lazy Functional Programs Based othe Spineless Tagless G-machine for the Java Virtual Machine''}, FLOPS 2001.

\bibitem[NP,EM-04]{PerryMeijer} Nigel Perry, Erik Meijer, \textit{,,Implementing functional languages on object-oriented virtual machines''}, IEE Proceedings on Software, 151(1):1-9, 2004.

\bibitem[OH-06]{Hunt} Oliver Hunt, \textit{,,The Provision of Non-Strictness, Higher Kinded Types
and Higher Ranked Types on an Object Oriented Virtual Machine''}, 2006.

\bibitem[EM,NP,AY-01]{MondrianImplDetails} Erik Meijer, Nigel Perry, Arjan van Yzendoorn, \textit{,,Scripting .NET using Mondrian''}, ECOOP 2001.

\bibitem[MM,MA,RB,AS-05]{Brazil} Monique Monteiro, Mauro Ara\'ujo, Rafael Borges, Andr\'e Santos,  \textit{,,Compiling Non-strict Functional Languages for the .NET Platform''}, Journal of Universal Computer Science, vol. 11, no. 7 (2005), 1255-1274.

\bibitem[HS,PS-90]{referentialTransparency} Harald Søndergaard, Peter Sestoft, \textit{,,Referential Transparency, Definiteness and Unfoldability''}, Acta Informatica 27, 505-517, 1990.

\bibitem[VH,SB,TG-19]{lazySpark} Val\'erie Hayot-Sasson, Shawn T Brown, Tristan Glatard, \textit{,,Performance Evaluation of Big Data Processing Strategies for Neuroimaging''}, CCGRID, 2019.

\bibitem[CO-96]{amortized} Chris Okasaki, \textit{,,The Role of Lazy Evaluation in Amortized Data Structures''} ICFP'96, 62-72, 1996.

\bibitem[PH-80]{SECDM} Peter Henderson, \textit{,,Functional Programming: Application and Implementation''},
Prentice-Hall, Englewood Cliffs, NJ, 1980.

\bibitem[K85]{G-Machine} Richard B. Kieburtz, \textit{,,The G-machine: a fast, graph-reduction evaluator''}, Technical Report CS/E-85-002, Dept. of Computer Science, Oregon Graduate Center, January 1985.

\bibitem[DT-79]{combinators} David A. Turner, \textit{,,A new implementation technique for applicative languages''}, Software -- Practice and Experience, 9:31–49, 1979.

\bibitem[MM,AS-86]{CAM} Michel Mauny, Asc\'ander Su\'arez, \textit{,,Implementing functional languages in the categorical abstract machine''}, In \texttt{Proceedings 1986 ACM Conference on Lisp and Functional Programming}, pages 266–278, Cambridge, Massachusetts, August 1986.

\bibitem[JF,SW-87]{TIM} Jon Fairbairn, Stuart Wray, \textit{,,Tim: a simple, lazy abstract machine to execute supercombinators''},  In \texttt{Proceedings of 1987 Functional Programming Languages and Computer Architecture Conference}, pages 34–45, Springer Verlag LNCS 274, September 1987.

\bibitem[SPJ-92]{STGM} Simon Peyton Jones, \textit{,,Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine''}, 1992.

\bibitem[IS,SPJ,DV-17]{demand analysis} Ilya Sergey, Simon Peyton Jones, Dimitrios Vytiniotis, \textit{,,Theory and Practice of Demand Analysis in Haskell''}, 2017.

\bibitem[HC-36]{Curry} Haskell Curry, \textit{,,Functionality in combinatory logic''}, \texttt{Proceedings
of the National Academy of Sciences (U.S.A.)}, XX, pp. 584—590, 1936.

\bibitem[SM,SPJ-04]{fastcurry} Simon Marlow, Simon Peyton Jones, \textit{,,Making a fast Curry: Push/Enter vs. Eval/Apply for Higher-order Languages''} ICFP'04, pp. 4-15, 2004.

\bibitem[MD-20]{ldftnVSdelegate} Marian Dziubiak, blog: \textit{,,Wskaźniki do funkcji w C\shrp''},
    \url{https://www.md-techblog.net.pl/2020/02/dotnet-function-pointer/}, 2020.

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
